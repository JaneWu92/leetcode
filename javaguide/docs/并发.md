## cache coherence
* cache coherence
    * 为什么？
        * 在多cpu的情况下，如果多个线程刚好都在多个cpu下，他们从主存中读一个东西后，会缓存在多级缓存中。
        * 各线程在各cpu的缓存中维护他们自己的副本，所以数据会不同步。
        * cache coherence是一种协议，能够解决这种共享变量的同步问题。
    * 需要保证两点
        * write propagation：我这里写了你那里要能看到
        * transaction serialization： 多地的顺序要跟在一地一样
    * 有两种设计思路
        * write invalidate: 如果一个缓存中的数据有新写，其他cpu监听到，缓存中相对应的数据都会变成invalid，这造成它要到主存读，也就读到了新的数据
        * write update: 如果一个缓存中的数据有新写，其他cpu监听到，它会相应地更新其他缓存中的数据。
        
## memory barrier
* 硬件级别的(cpu指令集级别)一种指令，可以让cpu保持指令的执行顺序。
* barrier就相当于一个屏障，你想调整指令的顺序，不能跨越屏障。所以比如你在指令a和指令b中间加了一个barrier，指令b就不可能跑到指令a前面先执行。
```aidl
Processor #1:
while(f == 0);
// Memory barrier required here
print x;

Processor #2:
x = 40;
// Memory barrier required here
f = 1;
```
* 还有要注意，内存屏障还可以保证**内存的可见性**！！！
```aidl
（1）LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。
（2）StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。
（3）LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。
（4）StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。
```
## volatile
* volatile和cache coherence的关系
    * 问题，既然有了cache coherence，我还要volatile做什么？
    * cache coherence是一种能力。就是你要用的时候可以去用。而不是它全部给你用上了。那多级缓存还有个鬼用。
    * cache coherence是操作系统提供的一种功能。volatile在设计的时候，可以用OS提供的这个API，来实现cache coherence。
    * 就像核武器，不是我造出来了就天天在打仗了。而是放着，我需要用的时候我就拿出来用。
* volatile的功能和实现
    * 指令重排的禁止
        * volatile的变量的access(read/write)，都会插入membar,这样指令就可以防止重排，多线程下就不会产生一些问题。
    * 线程间的内存可见性
        * volatile的变量的access(read/write)，都会保证缓存一致性。所以不会造成线程间看不到对方的latest write。
        * 也就是说，每次读写都会读写到最新值。
        * 实现。根据硬件架构的不一样，应该有不同的实现。
            * 比如说可以write update。每次写，都写到主存并且其他cache也刷新。
            * 或者说write invalidate。每次写，都写到主存并且让其他cache的变成invalid。这样其他invalid的cache要读的话，都会重新从主存读取。
    
## CAS
* implementation
    * in cpu arch level: lock cmpxchg(in x86 arch)
    * 我也不知道它是怎么做的，但它既能保证原子性，也能保证可见性。还不用加“锁”？
* 破案了！！！！
    * CAS只能保证原子性，不能保证可见性。
    * 所以CAS需要volatile的支持！请看AtomicLong，里面就是CAS + volatile 
    * 你去看java的unsafe底下实现的所有compareAndSet***，都是native方法，但是你会看到最后都是compareAndSetReference，
    * 并且comment里面它都是“This operation has memory semantics of a volatile read and write.“。是volatile的语义。
* 所以其实这里说的应该是两个东西，一个是高级编程语言里封装的CAS，一个是cpu指令集里的cmpxchg这两个东西。
* ========上面说的都错了=============
* cas能保证线程可见性，人家用的都是setObjectVolatile，不管你变量加没加volatile
## cmpxchg
* https://wiki.osdev.org/Atomic_operation
* in single processor single core, 
    * if an operation is implemented in a single cpu instruction is always **atomic**
    * if it required multiple cpu instruction, it will be atomic if it **disable interrupt**
* in multiprocessors or multicore,
    * to get atomic, you need to assert **"LOCK"** signal on the bus
* 问题
    * cmpxchg和cache coherence的关系
        * 先说single core底下是atomic的，okay如果是single core，也不存在cache竞争的情况，也不存在被打断的情况。所以没问题。
        * 再说multiprocessor底下：
            * 可见性和原子性都不能保证。前者是因为有各自的cache，后者是因为各个processor上的都能去cmpxchg。
            * 所以加lock前缀，做lock cmpxchg，这样bus就被锁上，只有自己可以操作主存。
                * 这是能保证原子性了。但是不知道可见性怎么保证的。
    
## @sun.misc.Contended
* 避免当前这个变量和其他变量在同一个cacheLine里。
* 这样当前变量改的话，其他变量即使没有改动，也会变成invalid，而需要重新从主存中往cache拉。性能就会有伤害。
* 这样来说这个东西应该一定是在volatile的时候加着用。因为如果不是volatile，根本没有在强制保持缓存一致性。
* 当前变量一定要是volatile，其他变量不一定要是volatile。
    * 因为当前变量是会把cache line设置成invalid，不管其他变量是不是volatile，invalid的cache line一定要从主存再取。
    * 当然这里还有另外一种可能，就是对于非volatile的变量，根本没有“cache line invalid”这一说。那就是另外一回事。

## unsafe
* getLongVolatile
    * 会直接main memory拿target地址的值，跳过所有cache
    * 和getLong的区别：前者跳过cache，后者会在cache先找，所以会有缓存不一致
    * 不需要拿的这个变量有任何vlatile的标识
* cas
    * 内部都是调compareAndSetReference
    * 它涉及到的变量**不需要**加volatile。请注意！！！
* unsafe的接口都不需要变量前面加volatile
    * 比如getReferenceVolatile和compareAndSetReference
    * 本身都是原子性和内存可见性的。因为都是直接操作的主存。
    * 那为什么还要volatile这个关系字
        * 用了这个关键字你就不需要用unsafe啦，单次读写就可以跟normal一样啦。不用再用unsafe的接口，多方便啊。
        
## Array element volatile
* volatile只能限制数组的reference，不能限制array element是volatile
* 所以直接arr[i] = value是不安全的，不能保证其他线程也看到这个变化
* 问题： LongAdder里面就是用的arr[i] = value这种做法，为什么会没有问题。
* AtomicIntegerArray
    * 安全的有可见性的array。都是通过unsafe的putVolatile,getVolatile，就是直接操作内存来实现的。  
    
## synchronied
object header：class pointer, mark word, array size
markword: ...., is bias, lock type, gc age    
    
    
### ReentrantReadWriteLock
* 主要就是一个目标：支持并发读
    * 我们知道线程安全有一个很容易的，就是加互斥锁
    * 也就是你任何的操作，都是排他的
    * 你无论要读写，都要去拿这个锁，也就是同一时间，只会有一个线程在做它的操作
    * 但是有这样的情况，就是其实我只需要在写的时候做同步。读你们可以随便同步读
    * 这种就要求，写的时候是排它的。但是读的时候是共享的。
    * 就有了这个锁
    * 所以一般会出现在写少读多的场景下 
    * 其实这样说来，你也可以直接搞个锁，写的时候加上不就行了。
    * 不过这个就有个问题，我希望写的时候也不能有人读。
    * 那你普通的锁就做不到了。一定得读写锁
        
    
    
### TheadPool    
* 4 java embeded TheadPool
    * newCachedThreadPool:              0, MAX_VALUE, 60s, SynchronousQueue
    * newFixedThreadPool:               n, n,         0,   LinkedBlockingQueue
    * newSingleThreadExecutor:          1, 1,         0,   LinkedBlockingQueue         
    * newSingleThreadScheduledExecutor: 1
* analyze
    * keepAliveTime
        * 这个参数，是要不要把线程回收掉，当数量在core~max的区间
        * 60的话就是，如果一个线程超过60s的空闲，并且当前线程数是大于core数的，它就会回收
        * 0的话，就是不回收，你开了几个我就一直放着
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    