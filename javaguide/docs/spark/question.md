### spark容错机制
* 分布式场景下容错的必要性
    * 分布式会涉及到很多台机器，肯定会出现机器故障，网络异常。所以容错很关键
* 分布式的容错一般是两种：数据检查点 和 记录数据的更新
    * 数据检查点
        * 对某一时刻记录完整的快照
    * 记录数据更新
        * 记录你所有的更新迭代，出现问题我可以去重做
* spark
    * 记录数据更新
        * 记录RDD的所有transform操作。这个可以称作lineage
        * 所以当某个节点挂了，这部分的数据可以重做
    * checkpoint
        * 直接把lineage切断，把当前的这个RDD的数据放进hdfs里。